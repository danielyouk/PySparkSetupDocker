{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark DataFrame example\n",
    "이 섹션에서는 Spark DataFrame을 생성하고 간단한 작업을 실행하는 방법을 보여줍니다. 예제는 작은 DataFrame에 있으므로 기능을 쉽게 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/10 13:36:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Spakr DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"sue\", 32),\n",
    "        (\"li\", 3),\n",
    "        (\"bob\", 75),\n",
    "        (\"heo\", 13),\n",
    "    ],\n",
    "    [\"first_name\", \"age\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       sue| 32|\n",
      "|        li|  3|\n",
      "|       bob| 75|\n",
      "|       heo| 13|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df1 = df.withColumn(\n",
    "    \"life_stage\",\n",
    "    when(col(\"age\") < 13, \"child\")\n",
    "    .when(col(\"age\").between(13, 19), \"teenager\")\n",
    "    .when(col('first_name'))\n",
    "    .otherwise(\"adult\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|first_name|age|life_stage|\n",
      "+----------+---+----------+\n",
      "|       sue| 32|     adult|\n",
      "|        li|  3|     child|\n",
      "|       bob| 75|     adult|\n",
      "|       heo| 13|  teenager|\n",
      "+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|       sue| 32|\n",
      "|        li|  3|\n",
      "|       bob| 75|\n",
      "|       heo| 13|\n",
      "+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|first_name|age|life_stage|\n",
      "+----------+---+----------+\n",
      "|       sue| 32|     adult|\n",
      "|       bob| 75|     adult|\n",
      "|       heo| 13|  teenager|\n",
      "+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.where(col(\"life_stage\").isin([\"teenager\", \"adult\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|   30.75|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df1.select(avg(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|life_stage|avg(age)|\n",
      "+----------+--------+\n",
      "|     adult|    53.5|\n",
      "|     child|     3.0|\n",
      "|  teenager|    13.0|\n",
      "+----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"life_stage\").avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|   30.75|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select avg(age) from {df}\", df=df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|life_stage|avg(age)|\n",
      "+----------+--------+\n",
      "|     adult|    53.5|\n",
      "|     child|     3.0|\n",
      "|  teenager|    13.0|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select life_stage, avg(age) from {df} group by life_stage\", df=df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.write.saveAsTable(\"some_people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|first_name|age|life_stage|\n",
      "+----------+---+----------+\n",
      "|       heo| 13|  teenager|\n",
      "|       bob| 75|     adult|\n",
      "|       sue| 32|     adult|\n",
      "|        li|  3|     child|\n",
      "+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from some_people\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO some_people VALUES ('frank', 4, 'child')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|first_name|age|life_stage|\n",
      "+----------+---+----------+\n",
      "|       heo| 13|  teenager|\n",
      "|     frank|  4|     child|\n",
      "|       bob| 75|     adult|\n",
      "|       sue| 32|     adult|\n",
      "|        li|  3|     child|\n",
      "+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from some_people\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----------+\n",
      "|first_name|age|life_stage|\n",
      "+----------+---+----------+\n",
      "|       heo| 13|  teenager|\n",
      "+----------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from some_people where life_stage='teenager'\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
